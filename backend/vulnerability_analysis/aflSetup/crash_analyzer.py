import os
import subprocess
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

class CrashAnalyzer:
    def __init__(self, binary_path, crashes_dir, llm):
        self.binary_path = binary_path
        self.crashes_dir = crashes_dir
        self.llm = llm

    def analyze_crashes(self):
        """Runs each crash input on the binary, captures output, and analyzes with LLM."""
        print("[+] Analyzing AFL++ crashes...")
        analysisOutput = []
        vuln_names = []

        if not os.path.exists(self.crashes_dir):
            print(f"[-] Crash directory `{self.crashes_dir}` not found!")
            return

        crash_files = [f for f in os.listdir(self.crashes_dir) if f.startswith("id:")]
        if not crash_files:
            print("[-] No crash files found.")
            return

        for crash_file in crash_files:
            crash_path = os.path.join(self.crashes_dir, crash_file)

            print(f"\n[*] Testing crash: {crash_file}")
            try:
                result = subprocess.run(
                    [self.binary_path, crash_path],
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    text=True,
                    timeout=5  # Prevent hangs
                )

                crash_output = result.stderr + result.stdout

                # Use LLM to analyze the crash
                analysis, vulns = self.analyze_with_llm(crash_output)

                analysisOutput.append(f"[*] Analysis for {crash_file}:\n{analysis}\n")
                vuln_names.extend(vulns)
            except subprocess.TimeoutExpired:
                print(f"[-] Crash {crash_file} caused a timeout.")
        
        return analysisOutput, vuln_names
                

    def analyze_with_llm(self, crash_output):
        """Passes crash output to LLM for vulnerability classification."""
        prompt = PromptTemplate(
            template=(
                # "Analyze the following program crash and determine the likely cause of the vulnerability. "
                # "Classify it into categories.\n\n"
                # "Crash Output:\n{crash_output}\n\n"
                # "KEEP YOUR ANALYSIS CONCISE"
                "You are a vulnerability analysis assistant. Analyze the following crash log and "
                "provide a short explanation of the likely cause. Then, list the vulnerability types it may fall under.\n\n"
                "Crash Output:\n{crash_output}\n\n"
                "Output format:\n"
                "Explanation: <concise explanation of crash cause>\n"
                "Vulnerability Types:\n"
                "- <type1>\n"
                "- <type2>\n"
                "... (if applicable)\n"
            ),
            input_variables=["crash_output"]
        )

        llm_chain = LLMChain(llm=self.llm, prompt=prompt)

        summary = llm_chain.run({"crash_output": crash_output})

        vulns = self.parse_vuln_names(summary)

        return summary, vulns

    def parse_vuln_names(self, summary):
        lines = summary.splitlines()
        vulnerabilities = []
        start_extracting = False

        for line in lines:
            if  "Vulnerability Types:" in line.strip():
                start_extracting = True
                continue
            if start_extracting:
                line = line.strip()
                if line.startswith("- "):
                    vulnerabilities.append(line[2:].strip())
                elif line == "":
                    break

        return vulnerabilities
