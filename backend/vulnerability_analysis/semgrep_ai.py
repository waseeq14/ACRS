import json
import subprocess
import csv
from langchain_openai import OpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from dotenv import load_dotenv
from langchain.chat_models import ChatOpenAI
import os

# Load environment variables
load_dotenv()
OpenAI.api_key = os.getenv("OPENAI_API_KEY")

class SarifResultAnalyzer:
    def __init__(self, filePath, llm, folder_path):
        self.llm = llm
        self.filePath = filePath
        self.folder_path = folder_path
        self.sarif_file_path = f"{self.folder_path}/results.sarif"
        self.llm = llm

    def run_semgrep(self):
        """Run Semgrep on the given file and generate SARIF output."""
        semgrep_command = f"semgrep --config p/c --severity ERROR --sarif --output {self.sarif_file_path} {self.filePath}"

        try:
            subprocess.run(semgrep_command, shell=True, check=True)
            print(f"Semgrep analysis completed. Results saved to {self.sarif_file_path}.")
        except subprocess.CalledProcessError as e:
            print(f"Error: Semgrep command failed with {e}.")
            raise

    def extract_and_analyze_results(self):
        results_list = []
        with open(self.sarif_file_path, 'r', encoding='utf-8-sig') as file:
            sarif_data = json.load(file)

        with open(f'{self.folder_path}/rules_analysis_results.csv', 'a', newline='') as csvfile:
            fieldnames = ['snippet', 'ai_analysis']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            if csvfile.tell() == 0:
                writer.writeheader()

            for run in sarif_data.get('runs', []):
                for result in run.get('results', []):
                    for location in result.get('locations', []):
                        physical_location = location.get('physicalLocation', {})
                        region = physical_location.get('region', {})
                        snippet = region.get('snippet', {})
                        snippet_text = snippet.get('text', None)

                        uri = physical_location.get('artifactLocation', {}).get('uri', None)

                        if snippet_text and uri:
                            #print(snippet_text)  # Debugging: print the snippet
                            snippet_result = {'snippet': snippet_text}
                            self.analyze_results_using_llm(snippet_result, snippet_text, uri, self.llm)
                            results_list.append(snippet_result)
                            writer.writerow(snippet_result)
                        else:
                            print("Warning: Missing required keys in SARIF data.")
        return results_list

    def analyze_results_using_llm(self, snippet_result, snippet_text, uri, llm):
        """Analyze a code snippet using GPT to identify vulnerabilities."""
        try:
            # Fetching file content using get_file_content function
            file_path = f"{uri}"
            code_content = get_file_content(uri)

            if code_content:
                # Define the prompt template for GPT
                prompt = PromptTemplate(
                    template=(
                        "You are an application security expert designated as a senior security engineer who reviews code to identify vulnerabilities and suggest fixes. "
                        "The following code snippet has been flagged as a vulnerability:\n\n{snippet_text}\n\n"
                        "Please conduct a thorough security review based on the following context:\n{surrounding_code_context}\n\n"
                        "Output format:\n"
                        "- Name the vulnerability.\n"
                        "- Show the vulnerable code.\n"
                        "- Explain how it can be exploited.\n"
                        "- Rate your confidence in the analysis.\n"
                    ),
                    input_variables=["snippet_text", "surrounding_code_context"]
                )

                # Run the LLM chain with the provided code context and snippet
                llm_chain = LLMChain(llm=llm, prompt=prompt)
                ai_analysis = llm_chain.run({"snippet_text": snippet_text, "surrounding_code_context": code_content})

                # Store the AI's analysis in the result
                snippet_result['ai_analysis'] = ai_analysis.strip()

            else:
                snippet_result['ai_analysis'] = "Could not retrieve file content."

        except KeyError as e:
            print(f"Warning: Could not find required key in SARIF data: {e}")
            snippet_result['ai_analysis'] = "Could not analyze due to missing data in the SARIF file."
        except Exception as e:
            print(f"Error: {e}")
            snippet_result['ai_analysis'] = f"An error occurred: {e}"

def get_file_content(uri):
    """Fetches file content based on the provided URI."""
    file_path = uri
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            content = file.read()
        return content
    except FileNotFoundError:
        print(f"Warning: Could not find file at path: {file_path}")
        return None


