import json
import subprocess
import csv
from langchain_openai import OpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from dotenv import load_dotenv
from langchain.chat_models import ChatOpenAI
import os

# Load environment variables
load_dotenv()
OpenAI.api_key = os.getenv("OPENAI_API_KEY")

class SarifResultAnalyzer:
    def __init__(self, filePath, llm, folder_path):
        self.llm = llm
        self.filePath = filePath
        self.folder_path = folder_path
        self.sarif_file_path = f"{self.folder_path}/results.sarif"

    def run_semgrep(self):
        """Run Semgrep on the given file and generate SARIF output."""
        semgrep_command = f"semgrep --config p/c --severity ERROR --sarif --output {self.sarif_file_path} {self.filePath}"

        try:
            subprocess.run(semgrep_command, shell=True, check=True)
            print(f"Semgrep analysis completed. Results saved to {self.sarif_file_path}.")
        except subprocess.CalledProcessError as e:
            print(f"Error: Semgrep command failed with {e}.")
            raise

    def extract_and_analyze_results(self):
        """Extracts Semgrep results and triggers LLM analysis."""
        results_list = []
        
        try:
            with open(self.sarif_file_path, 'r', encoding='utf-8-sig') as file:
                sarif_data = json.load(file)
        except FileNotFoundError:
            print("Warning: Semgrep did not generate a SARIF file. Running LLM analysis on entire file.")
            return self.analyze_entire_file_with_llm()

        with open(f'{self.folder_path}/rules_analysis_results.csv', 'a', newline='') as csvfile:
            fieldnames = ['snippet', 'ai_analysis']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            if csvfile.tell() == 0:
                writer.writeheader()

            vulnerabilities_found = False  # Flag to check if Semgrep found any vulnerabilities

            for run in sarif_data.get('runs', []):
                for result in run.get('results', []):
                    for location in result.get('locations', []):
                        physical_location = location.get('physicalLocation', {})
                        region = physical_location.get('region', {})
                        snippet = region.get('snippet', {})
                        snippet_text = snippet.get('text', None)

                        uri = physical_location.get('artifactLocation', {}).get('uri', None)

                        if snippet_text and uri:
                            vulnerabilities_found = True
                            snippet_result = {'snippet': snippet_text}
                            self.analyze_results_using_llm(snippet_result, snippet_text, uri, self.llm)
                            results_list.append(snippet_result)
                            writer.writerow(snippet_result)
                        else:
                            print("Warning: Missing required keys in SARIF data.")

            # If Semgrep finds nothing, run LLM analysis on the entire file
            if not vulnerabilities_found:
                print("No vulnerabilities found by Semgrep. Running LLM analysis on the full source code.")
                return self.analyze_entire_file_with_llm()

        return results_list

    def analyze_results_using_llm(self, snippet_result, snippet_text, uri, llm):
        """Analyze a code snippet using GPT to identify vulnerabilities."""
        try:
            file_path = uri
            code_content = get_file_content(uri)

            if code_content:
                prompt = PromptTemplate(
                    template=(
                        "You are an application security expert. The following code snippet was flagged as potentially vulnerable:\n\n"
                        "{snippet_text}\n\n"
                        "Context:\n{surrounding_code_context}\n\n"
                        "Perform a security analysis and provide:\n"
                        "- Name of the vulnerability (if any).\n"
                        "- Explain the risk and exploitation.\n"
                        "- Rate your confidence.\n"
                    ),
                    input_variables=["snippet_text", "surrounding_code_context"]
                )

                llm_chain = LLMChain(llm=llm, prompt=prompt)
                ai_analysis = llm_chain.run({"snippet_text": snippet_text, "surrounding_code_context": code_content})

                snippet_result['ai_analysis'] = ai_analysis.strip()
            else:
                snippet_result['ai_analysis'] = "Could not retrieve file content."

        except Exception as e:
            print(f"Error: {e}")
            snippet_result['ai_analysis'] = f"An error occurred: {e}"

    def analyze_entire_file_with_llm(self):
        """Analyze the entire file with LLM if Semgrep finds nothing."""
        code_content = get_file_content(self.filePath)
        if not code_content:
            print("Error: Unable to read source code.")
            return None

        prompt = PromptTemplate(
            template=(
                "You are a senior security expert reviewing the following source code:\n\n"
                "{source_code}\n\n"
                "Perform a security audit and provide:\n"
                "- List of vulnerabilities (if any).\n"
                "- Confidence level of the assessment.\n"
                "- If there's no visible vulnerability, mark it safe.\n"
                "KEEP IT CONCISE"
            ),
            input_variables=["source_code"]
        )

        llm_chain = LLMChain(llm=self.llm, prompt=prompt)
        ai_analysis=llm_chain.run({"source_code": code_content})

        print("LLM Security Analysis Report:\n", ai_analysis)
        return ai_analysis

def get_file_content(uri):
    """Fetches file content based on the provided URI."""
    try:
        with open(uri, 'r', encoding='utf-8') as file:
            return file.read()
    except FileNotFoundError:
        print(f"Warning: Could not find file at path: {uri}")
        return None