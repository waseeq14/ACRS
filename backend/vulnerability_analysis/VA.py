from io import StringIO
import os
import subprocess
from pyfiglet import Figlet
import warnings
from dotenv import load_dotenv
from contextlib import redirect_stderr
import time
import shutil
stderr_buffer = StringIO()
with redirect_stderr(stderr_buffer):
    from langchain.prompts import PromptTemplate
    from langchain_openai import OpenAI
    from langchain.chains import LLMChain
    from langchain.chat_models import ChatOpenAI
    from vulnerability_analysis.asan import AddressSanitizer
    from vulnerability_analysis.semgrep_ai import SarifResultAnalyzer
    from vulnerability_analysis.klee import KleeProcessor
    from vulnerability_analysis.klee2 import KleeProcessor2
    from vulnerability_analysis.classifyVuln import ClassifyVuln
    from vulnerability_analysis.aflSetup.afl_pipeline import AFLPIPELINE
    from vulnerability_analysis.aflSetup.crash_analyzer import CrashAnalyzer

    
warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", category=UserWarning)


class VA:
    def __init__(self, filePath, folder_path):
        self.filePath = filePath
        self.binaryPath = f"{self.filePath}_binary"
        self.folder_path = folder_path

    def setFilePath(self, newFilePath):
        self.filePath = newFilePath

    def ASAN(self):
        try:
            print("[+] PREPARING FOR ADDRESS SANITIZATION....")
            asan = AddressSanitizer(self.llm, self.filePath)
            asan.preprocess_code_with_main()
            asan.compile_with_asan()
            asan.run_asan()
            results = asan.analyze_asan_output()
            print("[+] ADDRESS SANITIZATION COMPLETED!")
            return results
        except Exception as e:
            print("[-] Error Occured (ASAN): ", e)

    def RULES(self):
        try:
            print("[+] PREPARING TO APPLY SOME STRICT RULES :3...")
            rules = SarifResultAnalyzer(self.filePath, self.llm, self.folder_path)
            rules.run_semgrep()
            results =  rules.extract_and_analyze_results()
            print("[+] RULES APPLIED!")
            return results
        except Exception as e:
            print("[-] Error Occured (RULES): ", e)

    def SYMBOLIC(self):
        try:
            print("[+] PREPARING TO KLEEN YOUR CODE. . . ")
            process = KleeProcessor(self.filePath, self.llm, self.folder_path)
            code = process.preprocess_code_with_llm()
            process.generate_llvm_ir()
            process.run_klee()
            results, vuln_names = process.parse_klee_output()
            print("[+] CODE HAS BEEN KLEENED!")
            return results, vuln_names, code
        except Exception as e:
            print("[-] Error Occured (KLEE): ", e)

    def SYMBOLIC2(self):
        try:
            print("[+] PREPARING TO KLEEN YOUR CODE. . . ")
            process = KleeProcessor2(self.filePath, self.llm, self.folder_path)
            segments = process.extract_vulnerable_segments()
            process.generate_llvm_ir_for_segments()
            result, vuln_names = process.run_klee_on_segments()
            print("[+] CODE HAS BEEN KLEENED!")
            return result, vuln_names, segments
        except Exception as e:
            print("[-] Error occured (KLEE): ", e)

    def getCWE(self):
        process = ClassifyVuln(self.llm, self.filePath)
        print(process.getVulns())
        cwes = process.getCWE()
        i = 1
        for cwe in cwes:
            print(f"{i}) ID#:{cwe[0]} - {cwe[1]} - Similarity Score: {cwe[2]}\n")
            i+=1
        return cwes

    def setupEnv(self):
        load_dotenv()
        OpenAI.api_key = os.getenv("OPENAI_API_KEY")
        self.llm = ChatOpenAI(model="gpt-4o", temperature=0)

    def fuzzer(self):
        try:
            afl = AFLPIPELINE(self.filePath, self.binaryPath , self.llm, self.folder_path)
            code = afl.make_fuzzer_friendly()
            seeds = afl.generate_seeds_with_llm()
            afl.compile_code()
            afl.run_afl_fuzz()
            crashes = CrashAnalyzer(self.binaryPath, f"{self.folder_path}/out/default/crashes", self.llm)
            result, vuln_names = crashes.analyze_crashes()
            return result, vuln_names, code, seeds
        except Exception as e:
            print("[-] Error occured during fuzzing: ",e)

    def startAnalysis(self, analysis_type):
        if analysis_type == "asan":
            result = self.fuzzer()
        elif analysis_type == "rules":
            result = self.RULES()
        elif analysis_type == "symbolic":
            result = self.SYMBOLIC()
        elif analysis_type == "symbolic2":
            result = self.SYMBOLIC2()
        elif analysis_type == "cwe":
            result = self.getCWE()
        else:
            return "error"

        return result

