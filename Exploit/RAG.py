import os
import subprocess
from markdown import markdown
from bs4 import BeautifulSoup
from langchain.vectorstores import FAISS
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain_text_splitters import CharacterTextSplitter
from dotenv import load_dotenv


class RAG:
    def __init__(self, md_directory, model="gpt-4o", chunk_size=1000, chunk_overlap=200):
        load_dotenv()
        self.md_directory = md_directory
        self.embeddings = OpenAIEmbeddings(api_key=os.getenv("OPENAI_API_KEY"))
        self.llm = ChatOpenAI(model=model, api_key=os.getenv("OPENAI_API_KEY"))
        self.text_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
        self.qa_chain = None

    def load_md_files_recursive(self):
        documents = []
        for root, _, files in os.walk(self.md_directory):
            for file_name in files:
                if file_name.endswith(".md"):
                    file_path = os.path.join(root, file_name)
                    with open(file_path, 'r', encoding='utf-8') as file:
                        md_content = file.read()
                    html = markdown(md_content)
                    plain_text = BeautifulSoup(html, 'html.parser').get_text()
                    documents.append(plain_text)
        return documents

    def process_source_file(self, source_file_path):
        """Process a source code file and return its content."""
        with open(source_file_path, 'r', encoding='utf-8') as file:
            return file.read()

    def prepare_documents(self):
        documents = self.load_md_files_recursive()
        return self.text_splitter.create_documents(documents)

    def build_faiss_index(self, split_docs, index_name="knowledge_base_faiss"):
        faiss_index = FAISS.from_documents(split_docs, self.embeddings)
        faiss_index.save_local(index_name)
        return faiss_index

    def load_faiss_index(self, index_name="knowledge_base_faiss"):
        return FAISS.load_local(index_name, self.embeddings, allow_dangerous_deserialization=True)

    def initialize_rag_pipeline(self, loaded_vectors):
        self.qa_chain = ConversationalRetrievalChain.from_llm(
            llm=self.llm,
            retriever=loaded_vectors.as_retriever()
        )

    def run_shell_command(self, command):
        """Run a shell command and return its output."""
        try:
            result = subprocess.check_output(command, shell=True, text=True, stderr=subprocess.STDOUT)
            return result.strip()
        except Exception as e:
            return f"Error running command '{command}': {str(e)}"

    def generate_exploit(self, source_file, binary_file, predefined_prompt):
        """Directly ask the LLM to describe the exploitation technique and generate the exploit."""
        # Load source code and binary information
        source_code = self.process_source_file(source_file)
        binary_info = self.run_shell_command(f"file {binary_file}")
        checksec_info = self.run_shell_command(f"checksec ./{binary_file}")
        gadgets = self.run_shell_command(f"ropper -f {binary_file}")

        # Combine all information into the prompt
        combined_prompt = (
            f"{predefined_prompt}\n\n"
            f"### Binary Information:\n{binary_info}\n{checksec_info}\ngadgets:{gadgets}\n\n"
            f"### Source Code:\n{source_code}\n\n"
            "Describe the technique for exploiting this binary ,based on the binary information provided to you, and justify why the chosen technqiue will work and provide a complete exploit script."
            "Dynamically find offset using cyclic IF THE RETURN OFFSET IS REQUIRED"            
        )

        # Get response from LLM
        response = self.qa_chain({"question": combined_prompt, "chat_history": []})
        return response['answer'].strip()


# Driver script
if __name__ == "__main__":
    # Initialize RAG
    md_directory = "RAG_data"
    rag = RAG(md_directory)

    # Prepare RAG data
    split_docs = rag.prepare_documents()
    rag.build_faiss_index(split_docs)
    loaded_vectors = rag.load_faiss_index()
    rag.initialize_rag_pipeline(loaded_vectors)

    # Provide input files
    source_file = "stack_ret2win.cpp"
    binary_file = "stack_ret2win"
    predefined_prompt = (
        "You are an expert in binary exploitation. Analyze the given binary and source code."
    )

    # Generate exploit
    exploit_script = rag.generate_exploit(source_file, binary_file, predefined_prompt)
    print("\nGenerated Exploit and Technique:\n", exploit_script)
